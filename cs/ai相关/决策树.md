用于解决分类问题

ID 属性 标签
## 1 简单概念

![image.png](https://gitee.com/xin_accio/pic-go-images/raw/master/20250927231103212.png)

根结点

内部结点

叶子结点（方形）


AI大模型使用UE8M0相比INT8的优势

DeepSeek-V3.1正式发布，采用专为下一代国产芯片设计的UE8M0 FP8 Scale参数精度。DeepSeek官方文档称此次更新让AI“更快地思考，拥有更强的Agent能力”。这一技术选择是其提升模型效率、并与国产芯片生态进行深度协同的关键一步。

在大模型的训练过程中，若都使用双精度或者单精度浮点数进行计算，会对内存产生极大消耗，目前现存的显卡都难以完成相关工作。为了提高模型效率，需要降低数据精度。本文中提到的UE8M0和INT8都是为了降低数据精度产生的不同量化格式。

## 2 **INT8****量化格式**

INT8是在降低数据精度过程中常用的数据类型。它是一种是对称均匀量化。通过量化算法，将一片连续的FP32数值范围，强制映射到有限的256个离散的整数点上。

然而，INT8的弊端很明显，为了覆盖少数异常值，不得不牺牲绝大多数正常数值的精度，导致模型效果急剧下降。

在传统CNN模型中，极端异常值较少出现，INT8足够完成工作。但在Transformer架构的动态计算特性，使得其激活值中极易产生异常值，INT8在这种场景下非常脆弱。

## 3 **UE8M0****量化格式**

       UE8M0本质上是一个8位指数、没有尾数的浮点表示。它具有非均匀的特性。它对小数值的表示相对密集，对大数值的表示相对稀疏。这更符合许多深度学习模型中激活值的分布特性（大部分值集中在零附近，少数是异常值）。因此，能够在不牺牲太多主流数值精度的前提下，同时覆盖到极端异常值，提供了比INT8大得多的有效动态范围。

    在鲁棒性方面，由于浮点表示法天生对巨大数值不敏感（用较低的精度表示它们），异常值对主流数值范围精度的影响要小得多。这使得量化后的模型更加稳定。

如果UE8M0是一个浮点格式，它的量化过程可以更直接。它更像是将FP32的指数位截断到8位，而不需要复杂的缩放因子和零点计算。这大大简化了量化的工作流，减少了工程上的复杂性，并且对校准数据的依赖性可能更低。